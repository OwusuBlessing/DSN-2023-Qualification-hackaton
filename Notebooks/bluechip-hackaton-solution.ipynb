{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7113433,"sourceType":"datasetVersion","datasetId":4101987}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bluechip-Summit \"Employee Attrition Prediction\" Hackathon\n\n### Table of Contents\n1. Importing Libraries\n2. Dataset Loading\n3. Data Preprocessing\n4. Feature Engineering\n   - Dropping Unnecessary Features\n   - Centering and Scaling of Numerical Features\n   - Winsorization\n   - Encoding Categorical Features\n   - Creating More Informative Features\n   - Feature Scaling\n5. Cross-Validation\n6. Training and Prediction\n7. Future Work\n\n### Acknowledgments\nI want to express my gratitude for the insightful guidance provided by the following notebooks:\n\n1. [Starting Strong - XGBoost, LightGBM, CatBoost](https://www.kaggle.com/code/khawajaabaidullah/starting-strong-xgboost-lightgbm-catboost): This notebook served as a solid foundation, offering valuable techniques in feature engineering and modeling. The insights gained significantly contributed to achieving a good Data Analytics (DA) score in my local cross-validation setup.\n\n2. [HR Analytics Final - Basic to Advanced EDA & ML](https://www.kaggle.com/code/ducminh0401/hr-analytics-final-basic-to-advanced-eda-ml): This notebook inspired various exploratory data analysis (EDA) approaches, enhancing my understanding of the data. It played a crucial role in shaping my EDA strategies.\n\n### Additional Note\nThe incorporation of the original dataset, as allowed by the competition, also played a pivotal role in boosting my overall score.\n\nThis notebook is a reflection of an enriching learning journey, and I am grateful for the valuable guidance offered by these resources.\n","metadata":{}},{"cell_type":"markdown","source":"### 1. Importing libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom pathlib import Path\nfrom pathlib import Path\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom IPython.display import display\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\nimport optuna\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","ExecuteTime":{"end_time":"2023-12-03T14:00:05.055429700Z","start_time":"2023-12-03T14:00:00.375434400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Dataset Loading","metadata":{}},{"cell_type":"code","source":"root_dir = Path('../input/bluechip-dataset')\n\n# id is not going to be an informative feature, so we're dropping it for train\n# but since we'll need test set's ids to make the submission file, so we'll save those in  a separate varible before dropping\ntrain = pd.read_csv(root_dir / \"train.csv\").drop(columns=\"id\")\ntest = pd.read_csv(root_dir / \"test.csv\")\ntest_idx = test.id #keep test ids for later submission\ntest = test.drop(columns=\"id\")\n\n# I have noticed that adding the original dataset improves score on the public leaderboard. So let's do that!\noriginal = pd.read_csv('../input/bluechip-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T13:30:09.424638Z","iopub.execute_input":"2023-12-06T13:30:09.425072Z","iopub.status.idle":"2023-12-06T13:30:09.497478Z","shell.execute_reply.started":"2023-12-06T13:30:09.425036Z","shell.execute_reply":"2023-12-06T13:30:09.495795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check number of samples in each dataset\nprint(f\"There are {train.shape[0]} samples in train data\")\nprint(f\"There are {test.shape[0]} samples in test data\")\nprint(f\"There are {original.shape[0]} samples in original data\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T13:30:09.500153Z","iopub.execute_input":"2023-12-06T13:30:09.500759Z","iopub.status.idle":"2023-12-06T13:30:09.507927Z","shell.execute_reply.started":"2023-12-06T13:30:09.500713Z","shell.execute_reply":"2023-12-06T13:30:09.506633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Data Preprocessing","metadata":{}},{"cell_type":"code","source":"#making feaure names of both train and original data the same\noriginal['Attrition'] = (original['Attrition'] == 'Yes').astype(np.int64)\n\n# in original data, id is termed as \"EmployeeNumber\", so let's drop it\noriginal.drop(columns=\"EmployeeNumber\", inplace=True)\n# now reordering the features in original dataset\noriginal = original[list(train.columns)]","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:01:52.911419900Z","start_time":"2023-12-03T14:01:52.782417800Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:10.035253Z","iopub.execute_input":"2023-12-06T13:30:10.035673Z","iopub.status.idle":"2023-12-06T13:30:10.045829Z","shell.execute_reply.started":"2023-12-06T13:30:10.035641Z","shell.execute_reply":"2023-12-06T13:30:10.044583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concatenating train and original data\ntrain_added = pd.concat([train, original]).reset_index(drop=True)\nlen(train_added)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:01:54.001992500Z","start_time":"2023-12-03T14:01:53.768917400Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:10.082791Z","iopub.execute_input":"2023-12-06T13:30:10.083180Z","iopub.status.idle":"2023-12-06T13:30:10.097831Z","shell.execute_reply.started":"2023-12-06T13:30:10.083147Z","shell.execute_reply":"2023-12-06T13:30:10.096612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for missing data\nprint(f\"Total missing data in train added with original data  is: {train_added.isnull().sum().sum()}\")\nprint(f\"Total missing data in test is: {train_added.isnull().sum().sum()}\")","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:01:55.222604700Z","start_time":"2023-12-03T14:01:55.044297400Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:10.118619Z","iopub.execute_input":"2023-12-06T13:30:10.118995Z","iopub.status.idle":"2023-12-06T13:30:10.133415Z","shell.execute_reply.started":"2023-12-06T13:30:10.118965Z","shell.execute_reply":"2023-12-06T13:30:10.131979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concatenating train and test\ny = train_added.Attrition\ndf = pd.concat([train_added.drop(columns=\"Attrition\"), test])","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:01:58.538661Z","start_time":"2023-12-03T14:01:58.387661200Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:10.149463Z","iopub.execute_input":"2023-12-06T13:30:10.149859Z","iopub.status.idle":"2023-12-06T13:30:10.161734Z","shell.execute_reply.started":"2023-12-06T13:30:10.149826Z","shell.execute_reply":"2023-12-06T13:30:10.160471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"#### Dropping unecesaary features","metadata":{}},{"cell_type":"code","source":"feats_to_drop = [col for col in df.columns if df[col].nunique()==1]\ncat_features = [col for col in df.columns if df[col].nunique() <= 20 and df[col].nunique() > 1]\ndf.drop(columns=feats_to_drop, inplace=True)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:02:00.501661700Z","start_time":"2023-12-03T14:02:00.324662600Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:11.490139Z","iopub.execute_input":"2023-12-06T13:30:11.490547Z","iopub.status.idle":"2023-12-06T13:30:11.522401Z","shell.execute_reply.started":"2023-12-06T13:30:11.490514Z","shell.execute_reply":"2023-12-06T13:30:11.521365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Centering and scaling of numerical  features","metadata":{}},{"cell_type":"code","source":"# center and scale\nCON_FEATURES = ['MonthlyRate', 'MonthlyIncome', 'DailyRate', 'HourlyRate', 'Age',\n                'DistanceFromHome', 'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole',\n                'YearsWithCurrManager', 'PercentSalaryHike', 'NumCompaniesWorked', 'TrainingTimesLastYear', \n                'YearsSinceLastPromotion']\nfor feature in CON_FEATURES:\n    mu = np.mean(df[feature])\n    sigma = np.std(df[feature])\n    df[feature] = (df[feature] - mu) / sigma","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:02:02.899661100Z","start_time":"2023-12-03T14:02:02.716662100Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:11.524531Z","iopub.execute_input":"2023-12-06T13:30:11.524873Z","iopub.status.idle":"2023-12-06T13:30:11.545970Z","shell.execute_reply.started":"2023-12-06T13:30:11.524844Z","shell.execute_reply":"2023-12-06T13:30:11.544780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Winsorization","metadata":{}},{"cell_type":"code","source":"df.loc[df['Education'] == 15, 'Education'] = 5 # 5 is the max possible value based on the original data\ndf.loc[df['JobLevel'] == 7, 'JobLevel'] = 5   # 5 is the max possible value based on the original data","metadata":{"execution":{"iopub.status.busy":"2023-12-06T13:30:11.547563Z","iopub.execute_input":"2023-12-06T13:30:11.547892Z","iopub.status.idle":"2023-12-06T13:30:11.554455Z","shell.execute_reply.started":"2023-12-06T13:30:11.547863Z","shell.execute_reply":"2023-12-06T13:30:11.553230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Encoding categorical features","metadata":{}},{"cell_type":"code","source":"#encode categorical features with ordinal encoder\nord_enc = OrdinalEncoder()\n\nord_enc.fit(df[cat_features])\n\ndf[cat_features] = ord_enc.transform(df[cat_features])\ndf.head()","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:02:04.585715300Z","start_time":"2023-12-03T14:02:04.385665Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:11.556868Z","iopub.execute_input":"2023-12-06T13:30:11.557981Z","iopub.status.idle":"2023-12-06T13:30:11.633082Z","shell.execute_reply.started":"2023-12-06T13:30:11.557934Z","shell.execute_reply":"2023-12-06T13:30:11.631672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature creation","metadata":{}},{"cell_type":"code","source":"#creating more informative features such as risk factors\ndef add_features(df):\n    df['MonthlyIncome/Age'] = df['MonthlyIncome'] / df['Age']\n    \n    df[\"Age_risk\"] = (df[\"Age\"] < 34).astype(int)\n    df[\"HourlyRate_risk\"] = (df[\"HourlyRate\"] < 60).astype(int)\n    df[\"Distance_risk\"] = (df[\"DistanceFromHome\"] >= 20).astype(int)\n    df[\"YearsAtCo_risk\"] = (df[\"YearsAtCompany\"] < 4).astype(int)\n    \n    df['NumCompaniesWorked'] = df['NumCompaniesWorked'].replace(0, 1)\n    df['AverageTenure'] = df[\"TotalWorkingYears\"] / df[\"NumCompaniesWorked\"]\n    # df['YearsAboveAvgTenure'] = df['YearsAtCompany'] - df['AverageTenure']\n    \n    df['JobHopper'] = ((df[\"NumCompaniesWorked\"] > 2) & (df[\"AverageTenure\"] < 2.0)).astype(int)\n    \n    df[\"AttritionRisk\"] = df[\"Age_risk\"] + df[\"HourlyRate_risk\"] + df[\"Distance_risk\"] + df[\"YearsAtCo_risk\"] + df['JobHopper']\n    \n    # More feature engineering ideas for modelling\n    df['feature_1'] = np.where(((df['StockOptionLevel'] >= 1) & \n                                (df['YearsAtCompany'] >= 3) & \n                                (df['YearsWithCurrManager'] >= 1)), 1, 0)\n    df['feature_2'] = np.where(((df['StockOptionLevel'] < 1) & \n                                (df['MonthlyIncome'] > 2700) & \n                                (df['OverTime'] == 'Yes')), 1, 0)\n    return df\ndf = add_features(df)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:02:06.688662Z","start_time":"2023-12-03T14:02:06.486668Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:12.450034Z","iopub.execute_input":"2023-12-06T13:30:12.450483Z","iopub.status.idle":"2023-12-06T13:30:12.471838Z","shell.execute_reply.started":"2023-12-06T13:30:12.450446Z","shell.execute_reply":"2023-12-06T13:30:12.470721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature transformation of numerical features by scaling ","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nfor feature in CON_FEATURES:\n    df[feature] = scaler.fit_transform(df[[feature]])\ndf\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-06T13:30:12.474152Z","iopub.execute_input":"2023-12-06T13:30:12.474812Z","iopub.status.idle":"2023-12-06T13:30:12.572090Z","shell.execute_reply.started":"2023-12-06T13:30:12.474758Z","shell.execute_reply":"2023-12-06T13:30:12.571037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Cross validation","metadata":{}},{"cell_type":"code","source":"#diving data into train and test sets back\nX_train = df.iloc[:len(train_added), :]\nX_test = df.iloc[len(train_added): , :]\nlen(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T13:30:12.573632Z","iopub.execute_input":"2023-12-06T13:30:12.574190Z","iopub.status.idle":"2023-12-06T13:30:12.582876Z","shell.execute_reply.started":"2023-12-06T13:30:12.574157Z","shell.execute_reply":"2023-12-06T13:30:12.581718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define dictionary to store models to be used and their respective names\n\n#xgboost\nxgb_params = {'n_estimators': 150,\n              'random_state':0,\n                 'max_depth': 3,\n                 'learning_rate': 0.1,\n                 'min_child_weight': 4,\n                 'subsample': 0.7,\n                 'colsample_bytree': 0.3,\n             'verbose':0}\n  \nxgb_clf = xgb.XGBClassifier(**xgb_params)\n\n#ight gbm\nlgbm_params = {'n_estimators': 407,\n               'random_state':0,\n                 'num_rounds': 274,\n                 'learning_rate': 0.1,\n                 'num_leaves': 195,\n                 'max_depth': 9,\n                 'min_data_in_leaf': 46,\n                 'lambda_l1': 0.01,\n                 'lambda_l2': 0.6,\n                 'min_gain_to_split': 1.42,\n                 'bagging_fraction': 0.45,\n                 'feature_fraction': 0.3,\n              'verbosity':-1}\nlgbm_clf = lgbm.LGBMClassifier(**lgbm_params)\n\n#catboost_params\ncatboost_params = {'loss_function': 'CrossEntropy',\n                     'learning_rate': 0.76,\n                   'random_state':0,\n                     'l2_leaf_reg': 0.014,\n                     'colsample_bylevel': 0.06,\n                     'depth': 1,\n                     'boosting_type': 'Plain',\n                     'bootstrap_type': 'Bernoulli',\n                     'min_data_in_leaf': 18,\n                     'one_hot_max_size': 14,\n                     'subsample': 0.99,\n                  'verbose':0}\n\ncatboost_clf = catboost.CatBoostClassifier(**catboost_params)\nmodels_dict = {\"xgboost\":xgb_clf,\"lightgbm\":lgbm_clf,\"catboost\":catboost_clf}\n","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:13:01.036442500Z","start_time":"2023-12-03T14:13:00.503443300Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:12.585481Z","iopub.execute_input":"2023-12-06T13:30:12.585966Z","iopub.status.idle":"2023-12-06T13:30:12.600384Z","shell.execute_reply.started":"2023-12-06T13:30:12.585923Z","shell.execute_reply":"2023-12-06T13:30:12.599330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_validate(X, y, models_dict):\n    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1337)\n    all_scores = {}\n    for model in models_dict.keys():\n        all_scores[model] = []\n    for name,model in models_dict.items():\n        print(f\"Cross Validation <-> {name}\")\n        print(\"-------------------------\")\n    \n        for fold_id, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n            \n            model.fit(X_tr, y_tr)\n            \n            y_pred = model.predict_proba(X_val)[:, 1]\n            \n            auc = roc_auc_score(y_val, y_pred)\n            \n            print(f\"Fold {fold_id} \\t auc: {auc}\")\n            \n            all_scores[name].append(auc)\n        \n        avg_auc = np.mean(all_scores[name])\n        print(f\"Avg AUC for {name} is : {avg_auc}\")\n        print(\"<--------------------------------->\")\n    for name, model in models_dict.items():\n        all_scores[name] = np.mean(np.array(all_scores[name]))\n    model_names = all_scores.keys()\n    model_scores = all_scores.values()\n    results = {\"Model\":model_names,\"AUC_Score\":model_scores}\n    results = pd.DataFrame.from_dict(results).sort_values(by = \"AUC_Score\",ascending=False)\n    # Plotting the bar chart\n    \n    plt.figure(figsize=(10, 6))\n    bars = plt.bar(results['Model'], results['AUC_Score'], color='skyblue')\n    plt.xlabel('Model')\n    plt.ylabel('Score')\n    plt.title('Model Scores in Descending Order')\n    plt.xticks(rotation=45, ha='right')  # Adjust rotation for better readability\n    \n    # Add text labels on top of each bar\n    for bar, score in zip(bars, results['AUC_Score']):\n        plt.text(bar.get_x() + bar.get_width() / 2 - 0.15, bar.get_height() + 0.5, f'{score:.4f}', ha='center')\n    \n    plt.xticks(rotation=45, ha='right')  # Adjust rotation for better readability\n\n    # Show the plot\n    plt.show()\n    #return results\n        ","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:13:07.181440900Z","start_time":"2023-12-03T14:13:06.952441Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:12.723348Z","iopub.execute_input":"2023-12-06T13:30:12.723728Z","iopub.status.idle":"2023-12-06T13:30:12.742070Z","shell.execute_reply.started":"2023-12-06T13:30:12.723699Z","shell.execute_reply":"2023-12-06T13:30:12.740877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_validate(\n    X = X_train,\n    y=y,\n    models_dict=models_dict\n)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:13:50.125918800Z","start_time":"2023-12-03T14:13:10.954442400Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:30:12.743879Z","iopub.execute_input":"2023-12-06T13:30:12.744224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Training and making prediction","metadata":{}},{"cell_type":"code","source":"#train on xgboost\nxgb_clf = xgb.XGBClassifier(**xgb_params)\nxgb_clf.fit(X_train, y, verbose=0)\n\n#train on lgm\nlgbm_clf = lgbm.LGBMClassifier(**lgbm_params)\nlgbm_clf.fit(X_train, y, verbose=False)\n\n#train with catboost\ncatboost_clf = catboost.CatBoostClassifier(**catboost_params)\ncatboost_clf.fit(X_train, y, verbose=False)","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2023-12-03T14:17:50.509585100Z","start_time":"2023-12-03T14:17:50.181586Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-06T13:28:19.921400Z","iopub.execute_input":"2023-12-06T13:28:19.921794Z","iopub.status.idle":"2023-12-06T13:28:21.425458Z","shell.execute_reply.started":"2023-12-06T13:28:19.921765Z","shell.execute_reply":"2023-12-06T13:28:21.424199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make predictions on test data for each cross validated model\nxgb_preds = xgb_clf.predict_proba(X_test)[:, 1]\nlgbm_preds = lgbm_clf.predict_proba(X_test)[:, 1]\ncat_preds = catboost_clf.predict_proba(X_test)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2023-12-06T13:28:21.427389Z","iopub.execute_input":"2023-12-06T13:28:21.427810Z","iopub.status.idle":"2023-12-06T13:28:21.461374Z","shell.execute_reply.started":"2023-12-06T13:28:21.427775Z","shell.execute_reply":"2023-12-06T13:28:21.460239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission 1 - xgboost","metadata":{}},{"cell_type":"code","source":"# Assign weights to each model\nsubmission = pd.DataFrame({\"id\": test_idx, \"Attrition\":xgb_preds})\nsubmission.head()\nsubmission.to_csv(\"Submission_1_XGB.csv\",index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T13:28:35.383418Z","iopub.execute_input":"2023-12-06T13:28:35.383856Z","iopub.status.idle":"2023-12-06T13:28:35.397926Z","shell.execute_reply.started":"2023-12-06T13:28:35.383823Z","shell.execute_reply":"2023-12-06T13:28:35.397008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission 3 - Blending xgboost and catboost","metadata":{}},{"cell_type":"code","source":"# Give more weight to XGB\nfinal_preds = np.column_stack([xgb_preds,\n                               cat_preds]).mean(axis=1)\nsubmission = pd.DataFrame({\"id\": test_idx, \"Attrition\":final_preds})\nsubmission.head()\nsubmission.to_csv(\"Submission_2_Blended_xg_cat.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T17:14:34.628667Z","iopub.execute_input":"2023-12-04T17:14:34.629094Z","iopub.status.idle":"2023-12-04T17:14:34.644303Z","shell.execute_reply.started":"2023-12-04T17:14:34.629061Z","shell.execute_reply":"2023-12-04T17:14:34.643159Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
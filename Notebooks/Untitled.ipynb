{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30974b1-9ce9-4a96-b273-71dcd09b9fa8",
   "metadata": {},
   "source": [
    "#### Table of contents\n",
    "- Importing libraries\n",
    "- Loading datasets\n",
    "- Feature Engineering\n",
    "- Cross validation\n",
    "- Model training\n",
    "- Model evaluation\n",
    "- Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c72ce-6ebf-450f-b0b9-8ec5e9d63d29",
   "metadata": {},
   "source": [
    "#### Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a00f9b-d7d0-4db2-a4c5-ffeb84001224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import boxcox\n",
    "import os\n",
    "%matplotlib inline\n",
    "np.random.seed(365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96d15d-3823-4f05-9ebe-b6e93a8e736a",
   "metadata": {},
   "source": [
    "#### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ca09958-11ee-48bb-8008-590a20891120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "data_path_train = r\"C:\\Users\\User\\Desktop\\Blessing_AI\\Free_AI_Classes_2023\\Data\\Housing_dataset_train.csv\"\n",
    "df_train = pd.read_csv(data_path_train)\n",
    "\n",
    "data_path_test = r\"C:\\Users\\User\\Desktop\\Blessing_AI\\Free_AI_Classes_2023\\Data\\Housing_dataset_test.csv\"\n",
    "df_test = pd.read_csv(data_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d715ccc-e49f-407f-a53d-b523dbce666d",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43cce26-109e-467d-bcd6-6208f2d4e2bd",
   "metadata": {},
   "source": [
    "##### Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aedbd69-dce0-416e-963e-611f9326f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing data in train data is 0\n",
      "Total missing data in test data  is 0\n"
     ]
    }
   ],
   "source": [
    "#Filling missing values\n",
    "#fill missing values in location with new class\n",
    "df_train[\"loc\"] = df_train[\"loc\"].fillna(\"Unknown\")\n",
    "df_test[\"loc\"] = df_test[\"loc\"].fillna(\"Unknown\")\n",
    "\n",
    "#fill missing values in title with new class\n",
    "df_train[\"title\"] = df_train[\"title\"].fillna(\"Unknown\")\n",
    "df_test[\"title\"] = df_test[\"title\"].fillna(\"Unknown\")\n",
    "\n",
    "#group hpuse title based on mode number of bedroom\n",
    "# Group by 'Category' and calculate the mode of 'Value' for each group\n",
    "def group_feature_by_feature_based_on_mode(by_feature,feature,df):\n",
    "    modes_values = []\n",
    "    titles = df[by_feature].unique()\n",
    "    for title in titles:\n",
    "        new_df = df[df[by_feature] == title]\n",
    "        mode_value =  new_df[feature].mode()[0]\n",
    "        modes_values.append(mode_value)\n",
    "    mode_dict = dict(zip(titles, modes_values))\n",
    "\n",
    "    return mode_dict\n",
    "\n",
    "#Fill missing values in bedroom by mode value of house title\n",
    "mode_values = group_feature_by_feature_based_on_mode(by_feature = \"title\",feature=\"bedroom\",df=df_train)\n",
    "#fill missing values by mode house title\n",
    "def fill_missing_by_mode(cols,mode_dict=mode_values):\n",
    "    col1 = cols[0]\n",
    "    col2 = cols[1]\n",
    "    if pd.isnull(col2):\n",
    "        return mode_dict[col1]\n",
    "    else:\n",
    "        return col2\n",
    "df_train[\"bedroom\"] = df_train[[\"title\",\"bedroom\"]].apply(fill_missing_by_mode,axis = 1)\n",
    "\n",
    "#Fill missing values in bathroon by mode value of house title\n",
    "mode_values = group_feature_by_feature_based_on_mode(by_feature = \"title\",feature=\"bathroom\",df=df_train)\n",
    "df_train[\"bathroom\"] = df_train[[\"title\",\"bathroom\"]].apply(fill_missing_by_mode,axis = 1)\n",
    "\n",
    "#Fill missing values in parking by mode value of house titl\n",
    "mode_values = group_feature_by_feature_based_on_mode(by_feature = \"title\",feature=\"parking_space\",df=df_train)\n",
    "df_train[\"parking_space\"] = df_train[[\"title\",\"parking_space\"]].apply(fill_missing_by_mode,axis = 1)\n",
    "\n",
    "print(f\"Total missing data in train data is {df_train.isnull().sum().sum()}\")\n",
    "print(f\"Total missing data in test data  is {df_test.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0c73f-cbd3-48e2-a685-e00263eada8c",
   "metadata": {},
   "source": [
    "##### Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "022177f8-c2d3-4057-8bb7-b045ee5684da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new feature to inducate geopolitical zone\n",
    "geo_states = {\"North_central\":[\"Benue\",\"Kogi\", \"Kwara\", \"Nasarawa\", \"Niger\", \"Plateau\"],\n",
    "\"North_East\":[\"Adamawa\", \"Bauchi\", \"Borno\", \"Gombe\", \"Taraba\", \"Yobe\"],\n",
    "\"North_West\":[\"Kaduna\", \"Katsina\", \"Kano\", \"Kebbi\", \"Sokoto\", \"Jigawa\",\"Zamfara\"],\n",
    "\"South_East\":[\"Abia\", \"Anambra\", \"Ebonyi\", \"Enugu\", \"Imo\"],\n",
    "\"South\":[\"Akwa Ibom\", \"Bayelsa\", \"Cross River\", \"Delta\", \"Edo\", \"Rivers\"],\n",
    "\"South_West\":[\"Ekiti\", \"Lagos\", \"Osun\", \"Ondo\", \"Ogun\", \"Oyo\"]}\n",
    "\n",
    "def add_geo_zone(df_train):\n",
    "        df_train[\"Geo_zone\"] = df_train[\"loc\"]\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"North_central\"]),\"Geo_zone\"] = \"North_central\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"North_East\"]),\"Geo_zone\"] = \"North_East\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"North_West\"]),\"Geo_zone\"] = \"North_West\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"South_East\"]),\"Geo_zone\"] = \"South_East\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"South\"]),\"Geo_zone\"] = \"South\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"South_West\"]),\"Geo_zone\"] = \"South_West\"\n",
    "        return df_train\n",
    "df_train = add_geo_zone(df_train = df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307fcc6-d712-4ef8-8e33-c3254f7f0a11",
   "metadata": {},
   "source": [
    "##### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f43e8a01-01b1-4732-b607-ee77fb55a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#squaring and logging output feature\n",
    "df_train[\"price_log\"] = np.log(df_train[\"price\"] + 1)\n",
    "df_train[\"price_sqrt\"] = np.sqrt(df_train[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3944b8ab-85a9-4fa1-9f55-87e871279b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lagos': 1, 'Bayelsa': 2, 'Rivers': 3, 'Akwa Ibom': 4, 'Delta': 5, 'Ogun': 6, 'Cross River': 7, 'Anambra': 8, 'Edo': 9, 'Oyo': 10, 'Ondo': 11, 'Enugu': 12, 'Osun': 13, 'Unknown': 14, 'Ekiti': 15, 'Kano': 16, 'Imo': 17, 'Nasarawa': 18, 'Katsina': 19, 'Plateau': 20, 'Benue': 21, 'Adamawa': 22, 'Kwara': 23, 'Niger': 24, 'Gombe': 25, 'Taraba': 26, 'Kaduna': 27, 'Bauchi': 28, 'Kogi': 29, 'Yobe': 30, 'Jigawa': 31, 'Borno': 32, 'Abia': 33, 'Zamfara': 34, 'Sokoto': 35, 'Ebonyi': 36, 'Kebbi': 37}\n"
     ]
    }
   ],
   "source": [
    "#Encode house location based mean houe price ranking\n",
    "#avergae pricing based on location\n",
    "location_ranks = list(df_train.groupby([\"loc\"])[\"price\"].mean().sort_values(ascending=False).index)\n",
    "location_ranks_dict = {}\n",
    "for i in location_ranks:\n",
    "    location_ranks_dict[i] = location_ranks.index(i) + 1\n",
    "print(location_ranks_dict)\n",
    "# Use the map() function to encode the data\n",
    "categories_train = df_train[\"loc\"]\n",
    "categories_test = df_test[\"loc\"]\n",
    "encoded_data_train = categories_train.map(location_ranks_dict)\n",
    "encoded_data_test = categories_test.map(location_ranks_dict)\n",
    "df_train[\"loc\"] = encoded_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0a7e418-dd22-4237-a3a0-b54d360694df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mansion': 1, 'Penthouse': 2, 'Detached duplex': 3, 'Unknown': 4, 'Townhouse': 5, 'Terrace duplex': 6, 'Semi-detached duplex': 7, 'Bungalow': 8, 'Flat': 9, 'Apartment': 10, 'Cottage': 11}\n"
     ]
    }
   ],
   "source": [
    "#Encode house location based mean houe price ranking\n",
    "#avergae pricing based on location\n",
    "location_ranks = list(df_train.groupby([\"title\"])[\"price\"].mean().sort_values(ascending=False).index)\n",
    "location_ranks_dict = {}\n",
    "for i in location_ranks:\n",
    "    location_ranks_dict[i] = location_ranks.index(i) + 1\n",
    "\n",
    "print(location_ranks_dict)\n",
    "# Use the map() function to encode the data\n",
    "categories_train = df_train[\"title\"]\n",
    "categories_test = df_test[\"title\"]\n",
    "encoded_data_train = categories_train.map(location_ranks_dict)\n",
    "encoded_data_test = categories_test.map(location_ranks_dict)\n",
    "df_train[\"title\"] = encoded_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "607c0bf2-7add-4057-8bb6-3ed1fca2f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'South': 1, 'South_West': 2, 'Unknown': 3, 'South_East': 4, 'North_central': 5, 'North_East': 6, 'North_West': 7}\n"
     ]
    }
   ],
   "source": [
    "#Encode house geopolotical zone  based mean houe price ranking\n",
    "#avergae pricing based on title\n",
    "location_ranks = list(df_train.groupby([\"Geo_zone\"])[\"price\"].mean().sort_values(ascending=False).index)\n",
    "location_ranks_dict = {}\n",
    "for i in location_ranks:\n",
    "    location_ranks_dict[i] = location_ranks.index(i) + 1\n",
    "print(location_ranks_dict)\n",
    "# Use the map() function to encode the data\n",
    "categories_train = df_train[\"Geo_zone\"]\n",
    "encoded_data_train = categories_train.map(location_ranks_dict)\n",
    "df_train[\"Geo_zone\"] = encoded_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94f3a205-c94a-4f33-856e-ded1ad7100c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>loc</th>\n",
       "      <th>title</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking_space</th>\n",
       "      <th>price</th>\n",
       "      <th>Geo_zone</th>\n",
       "      <th>price_log</th>\n",
       "      <th>price_sqrt</th>\n",
       "      <th>bed_bath_paking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3583</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1149999.565</td>\n",
       "      <td>7</td>\n",
       "      <td>13.955273</td>\n",
       "      <td>1072.380327</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2748</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1672416.689</td>\n",
       "      <td>2</td>\n",
       "      <td>14.329781</td>\n",
       "      <td>1293.219505</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9261</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3364799.814</td>\n",
       "      <td>2</td>\n",
       "      <td>15.028879</td>\n",
       "      <td>1834.339067</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2224</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2410306.756</td>\n",
       "      <td>4</td>\n",
       "      <td>14.695265</td>\n",
       "      <td>1552.516266</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10300</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2600700.898</td>\n",
       "      <td>5</td>\n",
       "      <td>14.771292</td>\n",
       "      <td>1612.668874</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  loc  title  bedroom  bathroom  parking_space        price  Geo_zone  \\\n",
       "0   3583   19      7        2         2              1  1149999.565         7   \n",
       "1   2748   11     10        1         2              4  1672416.689         2   \n",
       "2   9261   15      4        7         5              2  3364799.814         2   \n",
       "3   2224    8      3        5         2              4  2410306.756         4   \n",
       "4  10300   29      6        1         5              6  2600700.898         5   \n",
       "\n",
       "   price_log   price_sqrt  bed_bath_paking  \n",
       "0  13.955273  1072.380327              5.0  \n",
       "1  14.329781  1293.219505              7.0  \n",
       "2  15.028879  1834.339067             14.0  \n",
       "3  14.695265  1552.516266             11.0  \n",
       "4  14.771292  1612.668874             12.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting bedroom,bathroom and parking space to discrete variables\n",
    "df_train[[\"bedroom\",\"bathroom\",\"parking_space\"]] = df_train[[\"bedroom\",\"bathroom\",\"parking_space\"]].astype(int)\n",
    "df_test[[\"bedroom\",\"bathroom\",\"parking_space\"]] = df_test[[\"bedroom\",\"bathroom\",\"parking_space\"]].astype(int)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31a1b089-243f-4ed1-b537-91cf4cbfda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding total number of bedrooms,bathrooms and parking space\n",
    "df_train[\"bed_bath_paking\"] =  df_train[\"bedroom\"] + df_train[\"bathroom\"] + df_train[\"parking_space\"]\n",
    "df_test[\"bed_bath_paking\"] =  df_test[\"bedroom\"] + df_test[\"bathroom\"] + df_test[\"parking_space\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897ef58-9b1a-4cd7-8a5e-8cbf12b1a313",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15bde298-03bf-4a62-9de7-3496db588e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of models to be used\n",
    "models = {\"Linear_Regression\":LinearRegression(),\n",
    "          \"Random_Forest\":RandomForestRegressor(random_state=0),\"XGboost\":xgb.XGBRegressor(random_state=0),\n",
    "          \"Catboost\":CatBoostRegressor(random_state=0,silent=True),\"Gradient_boosting\":GradientBoostingRegressor(random_state=0)}\n",
    "\n",
    "#Calculate the number of bins using the Sturges method\n",
    "bins = int(np.ceil(np.log2(len(df_train)) + 1))\n",
    "#Bin the data using the Sturges method\n",
    "binned_data = pd.cut(df_train[\"price\"], bins=bins,labels=False)\n",
    "df_train[\"Bin_value\"] = binned_data\n",
    "\n",
    "#Divid data into dependent and independent variables\n",
    "X = df_train.drop([\"Bin_value\",\"price\",\"price_log\",\"ID\",\"price_sqrt\"],axis=1)\n",
    "y = df_train[\"Bin_value\"]\n",
    "target = \"price_log\"\n",
    "#skf = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "#Custom cross validation function\n",
    "def run(models):\n",
    "    #create empty dic for model and scores\n",
    "    scores = {}\n",
    "    for model in models.keys():\n",
    "        scores[model] = [] #create empty lsit to store model scores at on each fold\n",
    "    for name,model in models.items():\n",
    "        print(f\"Running -- {model}\")\n",
    "        print(\"-------------------------\")\n",
    "        for i,(train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            xtrain, xvalid = X.iloc[train_index], X.iloc[test_index]\n",
    "            ytrain, yvalid = df_train[target].iloc[train_index], df_train[target].iloc[test_index]\n",
    "            model.fit(xtrain, ytrain)\n",
    "            yvalid = np.exp(yvalid) - 1\n",
    "            #make predictions on validation data\n",
    "            preds_valid =  np.exp(model.predict(xvalid)) -1\n",
    "            rmse = mean_squared_error(yvalid, preds_valid,squared=False)\n",
    "            print(f\"Fold {i} score : \", rmse)\n",
    "            scores[name].append(rmse)\n",
    "        print(f\"{model} -- mean rmse {np.mean(scores[name])}\")\n",
    "        print()\n",
    "\n",
    "    #take the mean of scores for every model\n",
    "    for name, model in models.items():\n",
    "        scores[name] = np.mean(np.array(scores[name]))\n",
    "    model_names = scores.keys()\n",
    "    model_scores = scores.values()\n",
    "    results = {\"Model\":model_names,\"Rmse_score\":model_scores}\n",
    "    results = pd.DataFrame.from_dict(results) #create dictionary of model and corresponding mean rmse score\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb083a66-7bc1-432c-a978-9a53e1e39129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running -- LinearRegression()\n",
      "-------------------------\n",
      "Fold 0 score :  672365.0482334284\n",
      "Fold 1 score :  659569.4882421744\n",
      "Fold 2 score :  663019.814060372\n",
      "Fold 3 score :  689962.0846617826\n",
      "Fold 4 score :  683470.9811140407\n",
      "Fold 5 score :  677756.1085147084\n",
      "Fold 6 score :  688451.3732423781\n",
      "Fold 7 score :  669106.8144500032\n",
      "Fold 8 score :  736291.0143240849\n",
      "Fold 9 score :  735560.6236546115\n",
      "LinearRegression() -- mean rmse 687555.3350497584\n",
      "\n",
      "Running -- RandomForestRegressor(random_state=0)\n",
      "-------------------------\n",
      "Fold 0 score :  638413.8994211911\n",
      "Fold 1 score :  523460.57968888927\n",
      "Fold 2 score :  598448.5131817762\n",
      "Fold 3 score :  603657.4798439238\n",
      "Fold 4 score :  628132.3878249043\n",
      "Fold 5 score :  567013.2614946527\n",
      "Fold 6 score :  614438.3000945566\n",
      "Fold 7 score :  590526.5155155818\n",
      "Fold 8 score :  657957.4870324606\n",
      "Fold 9 score :  555875.6422062557\n",
      "RandomForestRegressor(random_state=0) -- mean rmse 597792.4066304192\n",
      "\n",
      "Running -- XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=0, ...)\n",
      "-------------------------\n",
      "Fold 0 score :  595913.7834545614\n",
      "Fold 1 score :  486263.78537617665\n",
      "Fold 2 score :  571902.9395477512\n",
      "Fold 3 score :  572793.2123719186\n",
      "Fold 4 score :  581024.264415216\n",
      "Fold 5 score :  561435.3334310524\n",
      "Fold 6 score :  586269.9052177643\n",
      "Fold 7 score :  577773.5963481776\n",
      "Fold 8 score :  595306.8551417901\n",
      "Fold 9 score :  528892.6710690694\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=0, ...) -- mean rmse 565757.6346373479\n",
      "\n",
      "Running -- <catboost.core.CatBoostRegressor object at 0x000001981E1A0610>\n",
      "-------------------------\n",
      "Fold 0 score :  581428.0917748234\n",
      "Fold 1 score :  482028.0194887658\n",
      "Fold 2 score :  563483.5672017476\n",
      "Fold 3 score :  550538.8847368027\n",
      "Fold 4 score :  566240.4122208203\n",
      "Fold 5 score :  543545.6304925561\n",
      "Fold 6 score :  578283.9616468361\n",
      "Fold 7 score :  559021.1305451711\n",
      "Fold 8 score :  596958.7987196182\n",
      "Fold 9 score :  534541.9820174052\n",
      "<catboost.core.CatBoostRegressor object at 0x000001981E1A0610> -- mean rmse 555607.0478844547\n",
      "\n",
      "Running -- GradientBoostingRegressor(random_state=0)\n",
      "-------------------------\n",
      "Fold 0 score :  568102.0458240584\n",
      "Fold 1 score :  495157.40113839007\n",
      "Fold 2 score :  551172.5224883802\n",
      "Fold 3 score :  557527.781643128\n",
      "Fold 4 score :  561302.7242180089\n",
      "Fold 5 score :  545167.2712150593\n",
      "Fold 6 score :  567020.7367283601\n",
      "Fold 7 score :  550775.5489949263\n",
      "Fold 8 score :  584938.5932937949\n",
      "Fold 9 score :  548729.4960458819\n",
      "GradientBoostingRegressor(random_state=0) -- mean rmse 552989.4121589989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = run(models = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5996ad0-5527-42eb-a812-8b0b12bba92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Rmse_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient_boosting</td>\n",
       "      <td>552989.412159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>555607.047884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGboost</td>\n",
       "      <td>565757.634637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>597792.406630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>687555.335050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model     Rmse_score\n",
       "4  Gradient_boosting  552989.412159\n",
       "3           Catboost  555607.047884\n",
       "2            XGboost  565757.634637\n",
       "1      Random_Forest  597792.406630\n",
       "0  Linear_Regression  687555.335050"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = results.sort_values(by=\"Rmse_score\",ascending=True)\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64bc4c6-eb45-4974-95ef-be44e265ba57",
   "metadata": {},
   "source": [
    "Comment : Gradient performs best compared t other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4415f3e-fc21-4d35-925d-7353ee6c848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "path = r\"C:\\Users\\User\\Desktop\\Blessing_AI\\Free_AI_Classes_2023\\Results\"\n",
    "os.chdir(path)\n",
    "sorted_df.to_csv(\"model_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa5340-bd26-48be-bb9a-a9da80ffd55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Training -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

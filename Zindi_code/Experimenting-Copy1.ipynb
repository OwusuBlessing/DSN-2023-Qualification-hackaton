{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30974b1-9ce9-4a96-b273-71dcd09b9fa8",
   "metadata": {},
   "source": [
    "#### Table of contents\n",
    "- Importing libraries\n",
    "- Loading datasets\n",
    "- Feature Engineering\n",
    "- Cross validation\n",
    "- Model training\n",
    "- Model evaluation\n",
    "- Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c72ce-6ebf-450f-b0b9-8ec5e9d63d29",
   "metadata": {},
   "source": [
    "#### Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2a00f9b-d7d0-4db2-a4c5-ffeb84001224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_error,r2_score\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor,RandomForestClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import boxcox\n",
    "import os\n",
    "%matplotlib inline\n",
    "import optuna\n",
    "from functools import partial\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96d15d-3823-4f05-9ebe-b6e93a8e736a",
   "metadata": {},
   "source": [
    "#### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ca09958-11ee-48bb-8008-590a20891120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "data_path_train = r\"C:\\Users\\User\\Desktop\\Blessing_AI\\Free_AI_Classes_2023\\Data\\Housing_dataset_train.csv\"\n",
    "df_train = pd.read_csv(data_path_train)\n",
    "data_path_test = r\"C:\\Users\\User\\Desktop\\Blessing_AI\\Free_AI_Classes_2023\\Data\\Housing_dataset_test.csv\"\n",
    "df_test = pd.read_csv(data_path_test)\n",
    "test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c90fc8b-e98c-44c6-a418-44566b5b160d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d715ccc-e49f-407f-a53d-b523dbce666d",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f22246-9197-4d34-aaaf-84132ada6793",
   "metadata": {},
   "source": [
    "##### Treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff03e87a-d36a-43d6-b8e6-d091cd3f01a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  0\n",
       "loc              1813\n",
       "title            1722\n",
       "bedroom          1799\n",
       "bathroom         1805\n",
       "parking_space    1811\n",
       "price               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c4417ea-5d0f-4075-9a6b-99294904f1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8856, 7)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dropna(subset=[\"loc\",\"title\",\"bedroom\"],inplace=True)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "533048c9-10a7-4c15-adbf-ef74c37e776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking square root, cube root and logging output feature\n",
    "df_train[\"price_log\"] = np.log(df_train[\"price\"] + 1)\n",
    "df_train[\"price_sqrt\"] = np.sqrt(df_train[\"price\"])\n",
    "df_train[\"price_cube\"] = np.cbrt(df_train[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1de2c61f-2b3b-4d68-9a19-ee079dc16259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # Separate the dataset into features (X) and target (y)\n",
    "def predict_nan_by_feature(df_train,x,y_):\n",
    "            X = df_train[x]\n",
    "            y = df_train[y_]\n",
    "            \n",
    "            # Identify rows with missing values (assuming NaN represents missing values)\n",
    "            rows_with_missing = df_train.isnull().any(axis=1)\n",
    "            \n",
    "            # Create a copy of the dataset for imputation\n",
    "            imputation_data = df_train.copy()\n",
    "            \n",
    "            # Separate the data into rows with missing values and rows without\n",
    "            data_with_missing = imputation_data[rows_with_missing]\n",
    "            data_without_missing = imputation_data[~rows_with_missing]\n",
    "            \n",
    "            # Separate the data without missing values into features and target\n",
    "            X_train = np.array(data_without_missing[x]).reshape(-1,1)\n",
    "            y_train = np.array(data_without_missing[y_]).reshape(-1,1)\n",
    "            \n",
    "            # Train a model (using RandomForestRegressor as an example)\n",
    "            model = RandomForestRegressor()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Drop the target column from the data with missing values\n",
    "            data_with_missing = np.array(data_with_missing[x]).reshape(-1,1)\n",
    "            \n",
    "            # Predict the missing values using the trained model\n",
    "            predicted_values = model.predict(data_with_missing)\n",
    "            \n",
    "            # Impute the predicted values back into the original dataset\n",
    "            imputation_data.loc[rows_with_missing, y_] = predicted_values\n",
    "            return imputation_data\n",
    "        \n",
    "    \n",
    "#predict missing values in bedroom  by price\n",
    "df_train = predict_nan_by_feature(df_train=df_train,x=\"price_log\",y_=\"bedroom\")\n",
    "    \n",
    "#predict missing values in bedroom  by price\n",
    "df_train = predict_nan_by_feature(df_train=df_train,x=\"price_log\",y_= \"bathroom\")\n",
    "\n",
    "#predict missing values in bedroom  by price\n",
    "df_train = predict_nan_by_feature(df_train=df_train,x=\"price_log\",y_=\"parking_space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b88238d7-edb2-4c16-b397-5e500ce0d59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID               0\n",
       "loc              0\n",
       "title            0\n",
       "bedroom          0\n",
       "bathroom         0\n",
       "parking_space    0\n",
       "price            0\n",
       "price_log        0\n",
       "price_sqrt       0\n",
       "price_cube       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4da56b8d-6ccc-4d96-8f03-a2a4cbc466e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8856, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43cce26-109e-467d-bcd6-6208f2d4e2bd",
   "metadata": {},
   "source": [
    "##### Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3aedbd69-dce0-416e-963e-611f9326f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Semi-detached duplex': 2.0, 'Apartment': 1.0, 'Detached duplex': 1.0, 'Terrace duplex': 1.0, 'Mansion': 1.0, 'Bungalow': 2.0, 'Penthouse': 1.0, 'Townhouse': 1.0, 'Flat': 2.0, 'Cottage': 1.0}\n",
      "{'Semi-detached duplex': 2.0, 'Apartment': 4.0, 'Detached duplex': 2.0, 'Terrace duplex': 4.0, 'Mansion': 2.0, 'Bungalow': 4.0, 'Penthouse': 4.0, 'Townhouse': 1.0, 'Flat': 2.0, 'Cottage': 4.0}\n",
      "Total missing data in train data is 0\n",
      "Total missing data in test data  is 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def group_feature_by_feature_based_on_mode(by_feature,feature,df):\n",
    "    modes_values = []\n",
    "    titles = list(df[by_feature].unique())\n",
    "    for title in titles:\n",
    "        new_df = df[df[by_feature] == title]\n",
    "        mode_value =  new_df[feature].mode()[0]\n",
    "        modes_values.append(mode_value)\n",
    "    mode_dict = dict(zip(titles, modes_values))\n",
    "    print(mode_dict)\n",
    "\n",
    "    return mode_dict\n",
    "#Fill missing values in bathroon by mode value of house title\n",
    "mode_values = group_feature_by_feature_based_on_mode(by_feature = \"title\",feature=\"bathroom\",df=df_train)\n",
    "#fill missing values by mode house title\n",
    "def fill_missing_by_mode(cols,mode_dict=mode_values):\n",
    "    col1 = cols[0]\n",
    "    col2 = cols[1]\n",
    "    if pd.isnull(col2):\n",
    "        return mode_dict[col1]\n",
    "    else:\n",
    "        return col2\n",
    "\n",
    "\n",
    "df_train[\"bathroom\"] = df_train[[\"title\",\"bathroom\"]].apply(fill_missing_by_mode,axis = 1)\n",
    "\n",
    "#Fill missing values in parking by mode value of house titl\n",
    "mode_values = group_feature_by_feature_based_on_mode(by_feature = \"title\",feature=\"parking_space\",df=df_train)\n",
    "df_train[\"parking_space\"] = df_train[[\"title\",\"parking_space\"]].apply(fill_missing_by_mode,axis = 1)\n",
    "\n",
    "print(f\"Total missing data in train data is {df_train.isnull().sum().sum()}\")\n",
    "print(f\"Total missing data in test data  is {df_test.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0c73f-cbd3-48e2-a685-e00263eada8c",
   "metadata": {},
   "source": [
    "##### Creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "022177f8-c2d3-4057-8bb7-b045ee5684da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new feature to inducate geopolitical zone\n",
    "geo_states = {\"North_central\":[\"Benue\",\"Kogi\", \"Kwara\", \"Nasarawa\", \"Niger\", \"Plateau\"],\n",
    "\"North_East\":[\"Adamawa\", \"Bauchi\", \"Borno\", \"Gombe\", \"Taraba\", \"Yobe\"],\n",
    "\"North_West\":[\"Kaduna\", \"Katsina\", \"Kano\", \"Kebbi\", \"Sokoto\", \"Jigawa\",\"Zamfara\"],\n",
    "\"South_East\":[\"Abia\", \"Anambra\", \"Ebonyi\", \"Enugu\", \"Imo\"],\n",
    "\"South\":[\"Akwa Ibom\", \"Bayelsa\", \"Cross River\", \"Delta\", \"Edo\", \"Rivers\"],\n",
    "\"South_West\":[\"Ekiti\", \"Lagos\", \"Osun\", \"Ondo\", \"Ogun\", \"Oyo\"]}\n",
    "\n",
    "def add_geo_zone(df_train):\n",
    "        df_train[\"Geo_zone\"] = df_train[\"loc\"]\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"North_central\"]),\"Geo_zone\"] = \"North_central\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"North_East\"]),\"Geo_zone\"] = \"North_East\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"North_West\"]),\"Geo_zone\"] = \"North_West\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"South_East\"]),\"Geo_zone\"] = \"South_East\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"South\"]),\"Geo_zone\"] = \"South\"\n",
    "        df_train.loc[df_train[\"loc\"].isin(geo_states[\"South_West\"]),\"Geo_zone\"] = \"South_West\"\n",
    "        return df_train\n",
    "df_train = add_geo_zone(df_train = df_train)\n",
    "df_test = add_geo_zone(df_train = df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307fcc6-d712-4ef8-8e33-c3254f7f0a11",
   "metadata": {},
   "source": [
    "##### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f43e8a01-01b1-4732-b607-ee77fb55a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking square root, cube root and logging output feature\n",
    "df_train[\"price_log\"] = np.log(df_train[\"price\"] + 1)\n",
    "df_train[\"price_sqrt\"] = np.sqrt(df_train[\"price\"])\n",
    "df_train[\"price_cube\"] = np.cbrt(df_train[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d347344-9f31-4a65-a178-c32ad11cb676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lagos': 15.164201750440764, 'Bayelsa': 14.886269812374607, 'Rivers': 14.807672123027194, 'Akwa Ibom': 14.743598986159991, 'Delta': 14.7148367100054, 'Ogun': 14.688530952997048, 'Cross River': 14.66378009139607, 'Anambra': 14.586379546363371, 'Oyo': 14.583855080167194, 'Edo': 14.578549286833502, 'Enugu': 14.569031980098126, 'Ondo': 14.55682652657201, 'Osun': 14.51749451121393, 'Ekiti': 14.513425575326508, 'Kano': 14.481509449571682, 'Nasarawa': 14.456433601921779, 'Imo': 14.442751966809734, 'Katsina': 14.41534982377515, 'Plateau': 14.389817938226313, 'Benue': 14.385893546358306, 'Kwara': 14.379143188461923, 'Adamawa': 14.375183993010024, 'Taraba': 14.365381784406637, 'Niger': 14.365256701446995, 'Kaduna': 14.36002146533926, 'Gombe': 14.33417112850962, 'Kogi': 14.30886528345092, 'Bauchi': 14.283238132256606, 'Yobe': 14.28075491158785, 'Jigawa': 14.27540458344726, 'Borno': 14.272336809801947, 'Abia': 14.271971038099514, 'Zamfara': 14.268366027934789, 'Sokoto': 14.247858492020116, 'Ebonyi': 14.230414894196633, 'Kebbi': 14.187803440516424}\n"
     ]
    }
   ],
   "source": [
    "#Encode house location based mean houe price ranking\n",
    "#avergae pricing based on location\n",
    "location_ranks = list(df_train.groupby([\"loc\"])[\"price_log\"].mean().sort_values(ascending=False).index)\n",
    "location_ranks_vals = list(df_train.groupby([\"loc\"])[\"price_log\"].mean().sort_values(ascending=False).values)\n",
    "location_ranks_dict = {}\n",
    "for i,j in zip(location_ranks,location_ranks_vals):\n",
    "    location_ranks_dict[i] = j\n",
    "print(location_ranks_dict)\n",
    "# Use the map() function to encode the data\n",
    "categories_train = df_train[\"loc\"]\n",
    "categories_test = df_test[\"loc\"]\n",
    "encoded_data_train = categories_train.map(location_ranks_dict)\n",
    "encoded_data_test = categories_test.map(location_ranks_dict)\n",
    "df_train[\"loc\"] = encoded_data_train\n",
    "df_test[\"loc\"] = encoded_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0a7e418-dd22-4237-a3a0-b54d360694df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mansion': 15.038973416880724, 'Penthouse': 14.728088824321503, 'Detached duplex': 14.556294050503396, 'Townhouse': 14.46983941963301, 'Terrace duplex': 14.401258616672163, 'Semi-detached duplex': 14.39968496038179, 'Flat': 14.301541574931527, 'Bungalow': 14.299494067095424, 'Apartment': 14.207836267874152, 'Cottage': 14.010785242580935}\n"
     ]
    }
   ],
   "source": [
    "#Encode house location based mean houe price ranking\n",
    "#avergae pricing based on location\n",
    "location_ranks = list(df_train.groupby([\"title\"])[\"price_log\"].mean().sort_values(ascending=False).index)\n",
    "location_ranks_vals = list(df_train.groupby([\"title\"])[\"price_log\"].mean().sort_values(ascending=False).values)\n",
    "location_ranks_dict = {}\n",
    "for i,j in zip(location_ranks,location_ranks_vals):\n",
    "    location_ranks_dict[i] = j\n",
    "print(location_ranks_dict)\n",
    "# Use the map() function to encode the data\n",
    "categories_train = df_train[\"title\"]\n",
    "categories_test = df_test[\"title\"]\n",
    "encoded_data_train = categories_train.map(location_ranks_dict)\n",
    "encoded_data_test = categories_test.map(location_ranks_dict)\n",
    "df_train[\"title\"] = encoded_data_train\n",
    "df_test[\"title\"] = encoded_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "607c0bf2-7add-4057-8bb6-3ed1fca2f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'South': 1, 'South_West': 2, 'South_East': 3, 'North_central': 4, 'North_West': 5, 'North_East': 6}\n"
     ]
    }
   ],
   "source": [
    "#Encode house geopolotical zone  based mean houe price ranking\n",
    "#avergae pricing based on title\n",
    "location_ranks = list(df_train.groupby([\"Geo_zone\"])[\"price_log\"].mean().sort_values(ascending=False).index)\n",
    "location_ranks_vals = list(df_train.groupby([\"Geo_zone\"])[\"price_log\"].mean().sort_values(ascending=False).values)\n",
    "location_ranks_dict = {}\n",
    "for i in location_ranks:\n",
    "    location_ranks_dict[i] = location_ranks.index(i) + 1\n",
    "print(location_ranks_dict)\n",
    "# Use the map() function to encode the data\n",
    "categories_train = df_train[\"Geo_zone\"]\n",
    "categories_test = df_test[\"Geo_zone\"]\n",
    "encoded_data_train = categories_train.map(location_ranks_dict)\n",
    "encoded_data_test = categories_test.map(location_ranks_dict)\n",
    "df_train[\"Geo_zone\"] = encoded_data_train\n",
    "df_test[\"Geo_zone\"] = encoded_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233756cc-f012-408c-8fba-58e2b1e8dcd6",
   "metadata": {},
   "source": [
    "#### Adding more informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94f3a205-c94a-4f33-856e-ded1ad7100c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>loc</th>\n",
       "      <th>title</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking_space</th>\n",
       "      <th>price</th>\n",
       "      <th>price_log</th>\n",
       "      <th>price_sqrt</th>\n",
       "      <th>price_cube</th>\n",
       "      <th>Geo_zone</th>\n",
       "      <th>bed_bath_paking</th>\n",
       "      <th>parking_bedroom_ratio</th>\n",
       "      <th>Rank_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3583</td>\n",
       "      <td>14.415350</td>\n",
       "      <td>14.399685</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1149999.565</td>\n",
       "      <td>13.955273</td>\n",
       "      <td>1072.380327</td>\n",
       "      <td>104.768942</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28.815035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2224</td>\n",
       "      <td>14.586380</td>\n",
       "      <td>14.556294</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2410306.756</td>\n",
       "      <td>14.695265</td>\n",
       "      <td>1552.516266</td>\n",
       "      <td>134.077974</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>29.142674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3003</td>\n",
       "      <td>14.415350</td>\n",
       "      <td>14.728089</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2043107.592</td>\n",
       "      <td>14.529983</td>\n",
       "      <td>1429.373147</td>\n",
       "      <td>126.890881</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>29.143439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12573</td>\n",
       "      <td>14.688531</td>\n",
       "      <td>14.299494</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1330213.036</td>\n",
       "      <td>14.100850</td>\n",
       "      <td>1153.348619</td>\n",
       "      <td>109.978316</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>28.988025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2624</td>\n",
       "      <td>14.886270</td>\n",
       "      <td>14.207836</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1891772.069</td>\n",
       "      <td>14.453025</td>\n",
       "      <td>1375.417053</td>\n",
       "      <td>123.677188</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>29.094106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID        loc      title  bedroom  bathroom  parking_space  \\\n",
       "0    3583  14.415350  14.399685        2         2              1   \n",
       "3    2224  14.586380  14.556294        5         2              4   \n",
       "7    3003  14.415350  14.728089        3         3              5   \n",
       "10  12573  14.688531  14.299494        1         2              6   \n",
       "11   2624  14.886270  14.207836        3         4              2   \n",
       "\n",
       "          price  price_log   price_sqrt  price_cube  Geo_zone  \\\n",
       "0   1149999.565  13.955273  1072.380327  104.768942         5   \n",
       "3   2410306.756  14.695265  1552.516266  134.077974         3   \n",
       "7   2043107.592  14.529983  1429.373147  126.890881         5   \n",
       "10  1330213.036  14.100850  1153.348619  109.978316         2   \n",
       "11  1891772.069  14.453025  1375.417053  123.677188         1   \n",
       "\n",
       "    bed_bath_paking  parking_bedroom_ratio   Rank_loc  \n",
       "0                 5               0.500000  28.815035  \n",
       "3                11               0.800000  29.142674  \n",
       "7                11               1.666667  29.143439  \n",
       "10                9               6.000000  28.988025  \n",
       "11                9               0.666667  29.094106  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting bedroom,bathroom and parking space to discrete variables\n",
    "df_train[[\"bedroom\",\"bathroom\",\"parking_space\"]] = df_train[[\"bedroom\",\"bathroom\",\"parking_space\"]].astype(int)\n",
    "df_test[[\"bedroom\",\"bathroom\",\"parking_space\"]] = df_test[[\"bedroom\",\"bathroom\",\"parking_space\"]].astype(int)\n",
    "\n",
    "#Adding total number of bedrooms,bathrooms and parking space\n",
    "df_train[\"bed_bath_paking\"] =  df_train[\"bedroom\"] + df_train[\"bathroom\"] + df_train[\"parking_space\"]\n",
    "df_test[\"bed_bath_paking\"] =  df_test[\"bedroom\"] + df_test[\"bathroom\"] + df_test[\"parking_space\"]\n",
    "\n",
    "#compare ratio of parking_space to bedroom\n",
    "df_train[\"parking_bedroom_ratio\"] =  df_train[\"parking_space\"] /  df_train[\"bedroom\"]\n",
    "df_test[\"parking_bedroom_ratio\"] =  df_test[\"parking_space\"] / df_test[\"bedroom\"]\n",
    "\n",
    "#Adding ranking of loaction and house title as a feature\n",
    "df_train[\"Rank_loc\"] = df_train[\"loc\"] + df_train[\"title\"]\n",
    "df_test[\"Rank_loc\"] = df_test[\"loc\"] +  df_test[\"title\"]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897ef58-9b1a-4cd7-8a5e-8cbf12b1a313",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "878dff35-4d28-4304-99fc-af6b4b4c3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the number of bins using the Sturges method\n",
    "bins = int(np.ceil(np.log2(len(df_train)) + 1))\n",
    "#Bin the data using the Sturges method\n",
    "binned_data = pd.cut(df_train[\"price_log\"], bins=bins,labels=False)\n",
    "df_train[\"Bin_value\"] = binned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15bde298-03bf-4a62-9de7-3496db588e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of models to be used\n",
    "models = {\"Linear_Regression\":LinearRegression(),\n",
    "          \"light_gradient_boistingt\":lgb.LGBMRegressor(random_state=0,verbose=0),\"XGboost\":xgb.XGBRegressor(random_state=0),\n",
    "          \"Catboost\":CatBoostRegressor(random_state=0,silent=True),\"Gradient_boosting\":GradientBoostingRegressor(random_state=0)}\n",
    "\n",
    "#Divid data into dependent and independent variables\n",
    "X = df_train.drop([\"Bin_value\",\"price\",\"price_log\",\"ID\",\"price_sqrt\",\"price_cube\"],axis=1)\n",
    "scale_features = [\"Rank_loc\",\"parking_bedroom_ratio\",\"bed_bath_paking\"]\n",
    "#use_cols = ['Rank_loc','title','bedroom','bed_bath_paking','loc','bathroom','parking_bedroom_ratio','Geo_zone']\n",
    "X = df_train[[\"title\",\"bedroom\",\"bathroom\",\"loc\",\"bed_bath_paking\",\"Rank_loc\",\"parking_space\",\"parking_bedroom_ratio\"]]\n",
    "cols = X.columns\n",
    "y = df_train[\"Bin_value\"]\n",
    "target = \"price_log\"\n",
    "#skf = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "#Custom cross validation function\n",
    "def run(models):\n",
    "    #create empty dic for model and scores\n",
    "    scores = {}\n",
    "    for model in models.keys():\n",
    "        scores[model] = [] #create empty lsit to store model scores at on each fold\n",
    "    for name,model in models.items():\n",
    "        print(f\"Running -- {name}\")\n",
    "        print(\"-------------------------\")\n",
    "        for i,(train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            xtrain, xvalid = X.iloc[train_index], X.iloc[test_index]\n",
    "            ytrain, yvalid = df_train[target].iloc[train_index], df_train[target].iloc[test_index]\n",
    "            model.fit(xtrain, ytrain)\n",
    "            yvalid = np.exp(yvalid) - 1\n",
    "            #make predictions on validation data\n",
    "            preds_valid =  np.exp(model.predict(xvalid)) - 1\n",
    "            rmse = mean_squared_error(yvalid, preds_valid,squared=False)\n",
    "            print(f\"Fold {i} score : \", rmse)\n",
    "            scores[name].append(rmse)\n",
    "        print(f\"{model} -- mean rmse {np.mean(scores[name])}\")\n",
    "        print()\n",
    "\n",
    "    #take the mean of scores for every model\n",
    "    for name, model in models.items():\n",
    "        scores[name] = np.mean(np.array(scores[name]))\n",
    "    model_names = scores.keys()\n",
    "    model_scores = scores.values()\n",
    "    results = {\"Model\":model_names,\"Rmse_score\":model_scores}\n",
    "    results = pd.DataFrame.from_dict(results) #create dictionary of model and corresponding mean rmse score\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb083a66-7bc1-432c-a978-9a53e1e39129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running -- Linear_Regression\n",
      "-------------------------\n",
      "Fold 0 score :  551115.6516341345\n",
      "Fold 1 score :  578676.3161392485\n",
      "Fold 2 score :  600049.9988608193\n",
      "Fold 3 score :  508258.79962035915\n",
      "Fold 4 score :  417506.1104045649\n",
      "Fold 5 score :  446529.47901438875\n",
      "Fold 6 score :  435114.6874244511\n",
      "Fold 7 score :  399868.53548630205\n",
      "Fold 8 score :  415727.7871992823\n",
      "Fold 9 score :  481124.5412731771\n",
      "LinearRegression() -- mean rmse 483397.1907056727\n",
      "\n",
      "Running -- light_gradient_boistingt\n",
      "-------------------------\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 0 score :  462512.04573357117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 1 score :  525906.6457154682\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 2 score :  497703.583229485\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 3 score :  481538.2731271902\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 4 score :  405025.41991009086\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 5 score :  479210.8596424491\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 6 score :  434273.36430844973\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 7 score :  382431.8253643354\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 8 score :  403811.3509810712\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Fold 9 score :  446172.9591624484\n",
      "LGBMRegressor(random_state=0, verbose=0) -- mean rmse 451858.6327174559\n",
      "\n",
      "Running -- XGboost\n",
      "-------------------------\n",
      "Fold 0 score :  434886.21862338047\n",
      "Fold 1 score :  551061.5978310156\n",
      "Fold 2 score :  443670.5735172783\n",
      "Fold 3 score :  493279.5833821738\n",
      "Fold 4 score :  423257.29149235564\n",
      "Fold 5 score :  537750.7102834259\n",
      "Fold 6 score :  472348.6951021453\n",
      "Fold 7 score :  395330.74078915385\n",
      "Fold 8 score :  423541.7313611108\n",
      "Fold 9 score :  542266.0914182103\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=0, ...) -- mean rmse 471739.323380025\n",
      "\n",
      "Running -- Catboost\n",
      "-------------------------\n",
      "Fold 0 score :  392911.0837119051\n",
      "Fold 1 score :  529883.0477552931\n",
      "Fold 2 score :  426515.6591020588\n",
      "Fold 3 score :  482230.15651107416\n",
      "Fold 4 score :  405426.83256739005\n",
      "Fold 5 score :  479793.4863974008\n",
      "Fold 6 score :  443361.8593024264\n",
      "Fold 7 score :  383113.08637933346\n",
      "Fold 8 score :  415784.2159047825\n",
      "Fold 9 score :  481441.3600868243\n",
      "<catboost.core.CatBoostRegressor object at 0x000001786533D3F0> -- mean rmse 444046.0787718488\n",
      "\n",
      "Running -- Gradient_boosting\n",
      "-------------------------\n",
      "Fold 0 score :  442501.32767711993\n",
      "Fold 1 score :  500329.26314067806\n",
      "Fold 2 score :  490412.1791852337\n",
      "Fold 3 score :  474967.72342950024\n",
      "Fold 4 score :  398832.17576577055\n",
      "Fold 5 score :  503091.85823464143\n",
      "Fold 6 score :  429658.0681393302\n",
      "Fold 7 score :  376487.58670485136\n",
      "Fold 8 score :  397261.99780997296\n",
      "Fold 9 score :  420063.2410313996\n",
      "GradientBoostingRegressor(random_state=0) -- mean rmse 443360.54211184976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = run(models = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "475cb05b-7a5d-4f3e-99e0-d3966fcd3659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "486000 - 471000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5996ad0-5527-42eb-a812-8b0b12bba92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Rmse_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient_boosting</td>\n",
       "      <td>443360.542112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>444046.078772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>light_gradient_boistingt</td>\n",
       "      <td>451858.632717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGboost</td>\n",
       "      <td>471739.323380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear_Regression</td>\n",
       "      <td>483397.190706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model     Rmse_score\n",
       "4         Gradient_boosting  443360.542112\n",
       "3                  Catboost  444046.078772\n",
       "1  light_gradient_boistingt  451858.632717\n",
       "2                   XGboost  471739.323380\n",
       "0         Linear_Regression  483397.190706"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = results.sort_values(by=\"Rmse_score\",ascending=True)\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9240a44e-65de-4bd2-9aa4-ccbe7a8eede3",
   "metadata": {},
   "source": [
    "#### Training and predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "408e1dc2-616c-4099-9766-685467767f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 score :  392911.0837119051\n",
      "Fold 1 score :  529883.0477552931\n",
      "Fold 2 score :  426515.6591020588\n",
      "Fold 3 score :  482230.15651107416\n",
      "Fold 4 score :  405426.83256739005\n",
      "Fold 5 score :  479793.4863974008\n",
      "Fold 6 score :  443361.8593024264\n",
      "Fold 7 score :  383113.08637933346\n",
      "Fold 8 score :  415784.2159047825\n",
      "Fold 9 score :  481441.3600868243\n",
      "Mean rmse :444046.0787718488\n",
      "Fold 0 score :  442501.32767711993\n",
      "Fold 1 score :  500329.26314067806\n",
      "Fold 2 score :  490412.1791852337\n",
      "Fold 3 score :  474967.72342950024\n",
      "Fold 4 score :  398832.17576577055\n",
      "Fold 5 score :  503091.85823464143\n",
      "Fold 6 score :  429658.0681393302\n",
      "Fold 7 score :  376487.58670485136\n",
      "Fold 8 score :  397261.99780997296\n",
      "Fold 9 score :  420063.2410313996\n",
      "Mean rmse :443360.54211184976\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>845</td>\n",
       "      <td>2.264470e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1924</td>\n",
       "      <td>1.081700e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10718</td>\n",
       "      <td>1.279374e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12076</td>\n",
       "      <td>8.748906e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12254</td>\n",
       "      <td>1.886399e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID         price\n",
       "0    845  2.264470e+06\n",
       "1   1924  1.081700e+06\n",
       "2  10718  1.279374e+06\n",
       "3  12076  8.748906e+06\n",
       "4  12254  1.886399e+06"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_predict(model):\n",
    "    scores = []\n",
    "    final_predictions = []\n",
    "    for i,(train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        xtrain, xvalid = X.iloc[train_index], X.iloc[test_index]\n",
    "        ytrain, yvalid = df_train[target].iloc[train_index], df_train[target].iloc[test_index]\n",
    "        xtest = df_test[cols].copy()\n",
    "\n",
    "        #Fit model\n",
    "        model.fit(xtrain, ytrain)\n",
    "        yvalid = np.exp(yvalid) - 1\n",
    "        #make predictions on validation data\n",
    "        preds_valid =  np.exp(model.predict(xvalid)) - 1\n",
    "\n",
    "\n",
    "        #make prediction on test data\n",
    "        test_preds = np.exp(model.predict(xtest))  - 1\n",
    "        final_predictions.append(test_preds)\n",
    "        rmse = mean_squared_error(yvalid, preds_valid,squared=False)\n",
    "        print(f\"Fold {i} score : \", rmse)\n",
    "        scores.append(rmse)\n",
    "\n",
    "    print(f\"Mean rmse :{np.array(scores).mean()}\")\n",
    "    return final_predictions\n",
    "model_cbr = CatBoostRegressor(silent=True,random_state=0)\n",
    "\n",
    "preds = train_predict(model_cbr);\n",
    "preds_new= np.mean(np.column_stack(preds),axis=1)\n",
    "sub = test[[\"ID\"]]\n",
    "sub[\"price_cat\"] = preds_new\n",
    "\n",
    "#Traing and predict with gradient boosting\n",
    "gb_model_1 = GradientBoostingRegressor(random_state=0,criterion=\"squared_error\")\n",
    "preds_gb = train_predict(gb_model_1);\n",
    "preds_gb= np.mean(np.column_stack(preds_gb),axis=1)\n",
    "sub[\"price_gb\"] = preds_gb\n",
    "\n",
    "#Take mean of the two models\n",
    "sub[\"price\"] = (sub[\"price_cat\"] + sub[\"price_gb\"])/2\n",
    "sub = sub.drop([\"price_gb\",\"price_cat\"],axis=1)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c0b381a-17ee-4f66-b474-1a4e49dd18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save submission file\n",
    "path = r\"C:\\Users\\User\\Desktop\\Blessing_AI\\Free_AI_Classes_2023\\Submissions\"\n",
    "os.chdir(path)\n",
    "sub.to_csv(\"xgb_cat_mean.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28f05d-7565-41d2-b5a0-e96570496679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
